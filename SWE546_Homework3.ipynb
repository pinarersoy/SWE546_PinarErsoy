{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Homework 3\n",
    "# Design a decision tree \n",
    "# Visualize your tree using pydot. \n",
    "# Try different depths and inpurity criteria (Gini and Information Gain). \n",
    "# Compare with KNN \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "from IPython.display \n",
    "\n",
    "#Importing Packages\n",
    "\n",
    "import Image  \n",
    "import pydotplus \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_with_gini(iris_data, iris_target, depth):\n",
    "    \n",
    "    classifier = tree.DecisionTreeClassifier(max_depth=depth) \n",
    "    # The maximum depth of the tree. \n",
    "    # If None, then nodes are expanded until all leaves are pure \n",
    "    # or until all leaves contain less than min_samples_split samples.\n",
    "    \n",
    "    \n",
    "    classifier = classifier.fit(iris_data, iris_target)\n",
    "    # Build a decision tree classifier from the training set (iris_data, iris_target).\n",
    "    \n",
    "    return classifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "# Iris Dataset loading phase\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(iris.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try Leave-One-Out method\n",
    "\n",
    "# Each learning set is created by taking all the samples except one, the test set being the sample left out.\n",
    "# Thus, for n samples, we have n different training sets and n different tests set. \n",
    "\n",
    "for check_depth_of_data in range(1,20):\n",
    "    \n",
    "    LeaveOneOut_Test = LeaveOneOut()\n",
    "    Sum_of_Total = 0\n",
    "    Gini_Result = 0\n",
    "    Entropy_Result = 0\n",
    "    KNN_Result = 0\n",
    "    \n",
    "    for train, test in LeaveOneOut_Test.split(iris.data):\n",
    "        Sum_of_Total = Sum_of_Total + 1\n",
    "\n",
    "        testData = list()\n",
    "        \n",
    "        testTarget = list()\n",
    "        \n",
    "        for i in train:\n",
    "            testData.append(iris.data[i])\n",
    "            testTarget.append(iris.target[i])\n",
    "        \n",
    "        # First classifier will be tested for decision tree with Gini\n",
    "        # Gini index - a criterion to minimize the probability of misclassification\n",
    "        classifier = tree_with_gini(testData, testTarget, check_depth_of_data)\n",
    "        \n",
    "        if classifier.predict(iris.data[test]) == iris.target[test]:\n",
    "            Gini_Result = Gini_Result + 1\n",
    "        \n",
    "        \n",
    "        # Second classifier will be tested for decision tree with Entropy\n",
    "        # Entropy - a way to measure impurity\n",
    "        classifier2 = create_tree_using_entropy(testData, testTarget, check_depth_of_data)\n",
    "        \n",
    "        # Predict the class labels for the provided data for Entropy\n",
    "        if classifier2.predict(iris.data[test]) == iris.target[test]:\n",
    "            Entropy_Result = Entropy_Result + 1\n",
    "        \n",
    "        \n",
    "        # Third classifier will be for KNN algorithm\n",
    "        classifier3 = neighbors.KNeighborsClassifier(1, weights='uniform') \n",
    "        # Classifier implementing the k-nearest neighbors vote\n",
    "        # uniform weighting: All points in each neighborhood are weighted equally.\n",
    "        \n",
    "        classifier3.fit(testData, testTarget)\n",
    "        \n",
    "        if classifier3.predict(iris.data[test]) == iris.target[test]:\n",
    "            KNN_Result = KNN_Result + 1\n",
    "            \n",
    "    # Print the results of the methods  \n",
    "    \n",
    "    # GINI results with max Depth and percentage\n",
    "    print \"Depth of Decision Tree \" + str(check_depth_of_data) + \" GINI Result:   %\" + str(Gini_Result*100/Sum_of_Total)\n",
    "\n",
    "    # Entropy results with max Depth and percentage\n",
    "    print \"Depth of Decision Tree \" + str(check_depth_of_data) + \" Entropy Result: %\" + str(Entropy_Result*100/Sum_of_Total)\n",
    "\n",
    "    # KNN results with max Depth and percentage\n",
    "    print \"Result of KNN method is %\" + str(KNN_Result*100/Sum_of_Total\n",
    " \n",
    "                                                                                       \n",
    "                                            \n",
    "# For KNN:\n",
    "# KNN determines neighborhoods, so there must be a distance metric. \n",
    "# This implies that all features must be numeric. \n",
    "# Distance metrics may be effected by varying scales between attributes and also high-dimensional space.\n",
    "                                            \n",
    "# For Decision Tree:\n",
    "# Decision Tree predicts a class for a given input vector. The attributes may be numeric or nominal.\n",
    "\n",
    "#COMMENT: \n",
    "# If you would like to find similar examples you could use K-NN. \n",
    "# If you want to classify examples you could use Decision Tree.                                          \n",
    "                                 \n",
    "                                            \n",
    "                                            \n",
    "# The Results of the program will be as the following:\n",
    "                                            \n",
    "# Results show that as the depth of the tree maximizes, the accuracy increases \n",
    "# With this dataset the final results are closer to each other \n",
    "                            \n",
    "                                            \n",
    "                                            \n",
    "#  Depth of Decision Tree 1 GINI Result:   %33\n",
    "#  Depth of Decision Tree 1 Entropy Result: %33\n",
    "\n",
    "#  Depth of Decision Tree 2 GINI Result:   %95\n",
    "#  Depth of Decision Tree 2 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 3 GINI Result:   %94\n",
    "#  Depth of Decision Tree 3 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 4 GINI Result:   %94\n",
    "#  Depth of Decision Tree 4 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 5 GINI Result:   %94\n",
    "#  Depth of Decision Tree 5 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 6 GINI Result:   %95\n",
    "#  Depth of Decision Tree 6 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 7 GINI Result:   %95\n",
    "#  Depth of Decision Tree 7 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 8 GINI Result:   %94\n",
    "#  Depth of Decision Tree 8 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 9 GINI Result:   %94\n",
    "#  Depth of Decision Tree 9 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 10 GINI Result:   %94\n",
    "#  Depth of Decision Tree 10 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 11 GINI Result:   %95\n",
    "#  Depth of Decision Tree 11 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 12 GINI Result:   %94\n",
    "#  Depth of Decision Tree 12 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 13 GINI Result:   %95\n",
    "#  Depth of Decision Tree 13 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 14 GINI Result:   %94\n",
    "#  Depth of Decision Tree 14 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 15 GINI Result:   %94\n",
    "#  Depth of Decision Tree 15 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 16 GINI Result:   %94\n",
    "#  Depth of Decision Tree 16 Entropy Result: %95\n",
    "\n",
    "#  Depth of Decision Tree 17 GINI Result:   %96\n",
    "#  Depth of Decision Tree 17 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 18 GINI Result:   %95\n",
    "#  Depth of Decision Tree 18 Entropy Result: %94\n",
    "\n",
    "#  Depth of Decision Tree 19 GINI Result:   %96\n",
    "#  Depth of Decision Tree 19 Entropy Result: %96\n",
    "\n",
    "#  Result of KNN method is  %96                             \n",
    "                            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
